{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "jobathon.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNtskl6k+lfkK3Vkem3JVMX",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vasist1987/HackerRank_Python/blob/master/jobathon.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nZxrHhSGiPlQ"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "pd.set_option('display.max_rows', 500)\n",
        "pd.set_option('display.max_columns', 500)\n",
        "pd.set_option('display.width', 1000)\n",
        "import lightgbm as lgb\n",
        "from lightgbm import LGBMClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "import sklearn.metrics\n",
        "!pip install --quiet optuna\n",
        "import optuna\n",
        "import os\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from imblearn.under_sampling import RandomUnderSampler"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gSUb_4n1mMGk"
      },
      "source": [
        "class dataImports():\n",
        "    \n",
        "    def __init__(self, df=None):\n",
        "        self.df = df\n",
        "        \n",
        "    def openZipFileCsv(self,zipPath,fileName):\n",
        "        zp=zipfile.ZipFile(zipPath,'r')\n",
        "        self.df= pd.read_csv(zp.open(fileName))\n",
        "        return self\n",
        "        \n",
        "    def import_Data_File(self,objectName,src_type,sheet=None):   \n",
        "        if src_type=='csv':\n",
        "            self.df=pd.read_csv(objectName)       \n",
        "        if src_type=='excel':\n",
        "            self.df=pd.read_excel(objectName, sheet_name = None)\n",
        "        return self\n",
        "    def import_Data_Database(self,src_type,tbname,server_name,db_name,uname,pwd):\n",
        "        if src_type=='mssql':\n",
        "            con=getConnectionMSSQL(server_name,db_name,uname,pwd)\n",
        "            self.df=selectFromDb(tbname,server_name,db_name,uname,pwd,con)\n",
        "        return self\n",
        "        "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D5ByeUY3lsFK"
      },
      "source": [
        "df_train=(dataImports().import_Data_File('/content/train_s3TEQDk.csv','csv')).df\n",
        "df_test=(dataImports().import_Data_File('/content/test_mSzZ8RL.csv','csv')).df\n",
        "sample_submission=(dataImports().import_Data_File('/content/sample_submission_eyYijxG.csv','csv')).df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m3DSxmHimJGl",
        "outputId": "e89d7ff3-df2c-40c2-fcea-5369360a8280"
      },
      "source": [
        "df_train.info()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 245725 entries, 0 to 245724\n",
            "Data columns (total 11 columns):\n",
            " #   Column               Non-Null Count   Dtype \n",
            "---  ------               --------------   ----- \n",
            " 0   ID                   245725 non-null  object\n",
            " 1   Gender               245725 non-null  object\n",
            " 2   Age                  245725 non-null  int64 \n",
            " 3   Region_Code          245725 non-null  object\n",
            " 4   Occupation           245725 non-null  object\n",
            " 5   Channel_Code         245725 non-null  object\n",
            " 6   Vintage              245725 non-null  int64 \n",
            " 7   Credit_Product       216400 non-null  object\n",
            " 8   Avg_Account_Balance  245725 non-null  int64 \n",
            " 9   Is_Active            245725 non-null  object\n",
            " 10  Is_Lead              245725 non-null  int64 \n",
            "dtypes: int64(4), object(7)\n",
            "memory usage: 20.6+ MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UInRrV0emUn2",
        "outputId": "f82d7631-b5db-4752-dc35-ff0a9ba9b112"
      },
      "source": [
        "df_test.info()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 105312 entries, 0 to 105311\n",
            "Data columns (total 10 columns):\n",
            " #   Column               Non-Null Count   Dtype \n",
            "---  ------               --------------   ----- \n",
            " 0   ID                   105312 non-null  object\n",
            " 1   Gender               105312 non-null  object\n",
            " 2   Age                  105312 non-null  int64 \n",
            " 3   Region_Code          105312 non-null  object\n",
            " 4   Occupation           105312 non-null  object\n",
            " 5   Channel_Code         105312 non-null  object\n",
            " 6   Vintage              105312 non-null  int64 \n",
            " 7   Credit_Product       92790 non-null   object\n",
            " 8   Avg_Account_Balance  105312 non-null  int64 \n",
            " 9   Is_Active            105312 non-null  object\n",
            "dtypes: int64(3), object(7)\n",
            "memory usage: 8.0+ MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 222
        },
        "id": "KgpjpoJITLaQ",
        "outputId": "5d5e7397-1dc3-43cd-fd05-6d3d2683a64d"
      },
      "source": [
        "df_train.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "      <th>Gender</th>\n",
              "      <th>Age</th>\n",
              "      <th>Region_Code</th>\n",
              "      <th>Occupation</th>\n",
              "      <th>Channel_Code</th>\n",
              "      <th>Vintage</th>\n",
              "      <th>Credit_Product</th>\n",
              "      <th>Avg_Account_Balance</th>\n",
              "      <th>Is_Active</th>\n",
              "      <th>Is_Lead</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>NNVBBKZB</td>\n",
              "      <td>Female</td>\n",
              "      <td>73</td>\n",
              "      <td>RG268</td>\n",
              "      <td>Other</td>\n",
              "      <td>X3</td>\n",
              "      <td>43</td>\n",
              "      <td>No</td>\n",
              "      <td>1045696</td>\n",
              "      <td>No</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>IDD62UNG</td>\n",
              "      <td>Female</td>\n",
              "      <td>30</td>\n",
              "      <td>RG277</td>\n",
              "      <td>Salaried</td>\n",
              "      <td>X1</td>\n",
              "      <td>32</td>\n",
              "      <td>No</td>\n",
              "      <td>581988</td>\n",
              "      <td>No</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>HD3DSEMC</td>\n",
              "      <td>Female</td>\n",
              "      <td>56</td>\n",
              "      <td>RG268</td>\n",
              "      <td>Self_Employed</td>\n",
              "      <td>X3</td>\n",
              "      <td>26</td>\n",
              "      <td>No</td>\n",
              "      <td>1484315</td>\n",
              "      <td>Yes</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>BF3NC7KV</td>\n",
              "      <td>Male</td>\n",
              "      <td>34</td>\n",
              "      <td>RG270</td>\n",
              "      <td>Salaried</td>\n",
              "      <td>X1</td>\n",
              "      <td>19</td>\n",
              "      <td>No</td>\n",
              "      <td>470454</td>\n",
              "      <td>No</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>TEASRWXV</td>\n",
              "      <td>Female</td>\n",
              "      <td>30</td>\n",
              "      <td>RG282</td>\n",
              "      <td>Salaried</td>\n",
              "      <td>X1</td>\n",
              "      <td>33</td>\n",
              "      <td>No</td>\n",
              "      <td>886787</td>\n",
              "      <td>No</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         ID  Gender  Age Region_Code     Occupation Channel_Code  Vintage Credit_Product  Avg_Account_Balance Is_Active  Is_Lead\n",
              "0  NNVBBKZB  Female   73       RG268          Other           X3       43             No              1045696        No        0\n",
              "1  IDD62UNG  Female   30       RG277       Salaried           X1       32             No               581988        No        0\n",
              "2  HD3DSEMC  Female   56       RG268  Self_Employed           X3       26             No              1484315       Yes        0\n",
              "3  BF3NC7KV    Male   34       RG270       Salaried           X1       19             No               470454        No        0\n",
              "4  TEASRWXV  Female   30       RG282       Salaried           X1       33             No               886787        No        0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 195
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZzgBIx90VXcD",
        "outputId": "ea9fd62a-3d6d-4e4e-81ac-7ed97a3a7890"
      },
      "source": [
        "df_train.columns"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['ID', 'Gender', 'Age', 'Region_Code', 'Occupation', 'Channel_Code', 'Vintage', 'Credit_Product', 'Avg_Account_Balance', 'Is_Active', 'Is_Lead'], dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 196
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IE5n-aRvUI4P"
      },
      "source": [
        "#Label Encoding for object to numeric conversion\n",
        "objList = ['Gender','Region_Code','Occupation','Channel_Code','Credit_Product','Is_Active']\n",
        "lbe = LabelEncoder()\n",
        "for feat in objList:\n",
        "    lbe.fit(df_train[feat].astype('str').values)\n",
        "    diz_map_train = dict(zip(lbe.classes_, lbe.transform(lbe.classes_)+1))\n",
        "\n",
        "    for i in set(df_test[feat].astype('str')).difference(df_train[feat].astype('str')):\n",
        "        diz_map_train[i] = 0\n",
        "\n",
        "    df_train[feat] = [diz_map_train[i] for i in df_train[feat].astype('str').values]\n",
        "    df_test[feat] = [diz_map_train[i] for i in df_test[feat].astype('str').values]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8pWZ7OoUT1Io",
        "outputId": "6fd7cf48-cbac-4441-8374-25feb294bd8b"
      },
      "source": [
        "df_train.Is_Lead.value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    187437\n",
              "1     58288\n",
              "Name: Is_Lead, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 198
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ibri9UCGj4jH"
      },
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "# fit scaler on training data\n",
        "norm = MinMaxScaler().fit(df_train[['Age', 'Region_Code', 'Vintage', 'Avg_Account_Balance']])\n",
        "X_train_norm=df_train\n",
        "X_test_norm=df_test\n",
        "# transform training data\n",
        "X_train_norm[['Age', 'Region_Code', 'Vintage', 'Avg_Account_Balance']] = norm.transform(df_train[['Age', 'Region_Code', 'Vintage', 'Avg_Account_Balance']])\n",
        "\n",
        "# transform testing dataabs\n",
        "X_test_norm[['Age', 'Region_Code', 'Vintage', 'Avg_Account_Balance']] = norm.transform(df_test[['Age', 'Region_Code', 'Vintage', 'Avg_Account_Balance']])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "yqMjx5QhQZ0I",
        "outputId": "c716e877-442d-4ea4-bde3-721081600d10"
      },
      "source": [
        "\n",
        "for i in X_train_norm.select_dtypes(exclude = \"object\").columns:\n",
        "  print(i)\n",
        "  plt.figure(figsize=(8,5))\n",
        "  sns.boxplot(i,data=X_train_norm)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Gender\n",
            "Age\n",
            "Region_Code\n",
            "Occupation\n",
            "Channel_Code\n",
            "Vintage\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/seaborn/_decorators.py:43: FutureWarning:\n",
            "\n",
            "Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/seaborn/_decorators.py:43: FutureWarning:\n",
            "\n",
            "Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/seaborn/_decorators.py:43: FutureWarning:\n",
            "\n",
            "Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/seaborn/_decorators.py:43: FutureWarning:\n",
            "\n",
            "Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/seaborn/_decorators.py:43: FutureWarning:\n",
            "\n",
            "Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/seaborn/_decorators.py:43: FutureWarning:\n",
            "\n",
            "Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Credit_Product\n",
            "Avg_Account_Balance\n",
            "Is_Active\n",
            "Is_Lead\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/seaborn/_decorators.py:43: FutureWarning:\n",
            "\n",
            "Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/seaborn/_decorators.py:43: FutureWarning:\n",
            "\n",
            "Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/seaborn/_decorators.py:43: FutureWarning:\n",
            "\n",
            "Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/seaborn/_decorators.py:43: FutureWarning:\n",
            "\n",
            "Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 467
        },
        "id": "dvcvKSzKS2nh",
        "outputId": "8c80ec15-b21f-4f12-8bc7-add809c6f4e6"
      },
      "source": [
        "#df_train.Avg_Account_Balance.describe()\n",
        "perc =[.20, .40, .60, .80, .90, .95,.99]\n",
        "df_test.describe(percentiles = perc)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Gender</th>\n",
              "      <th>Age</th>\n",
              "      <th>Region_Code</th>\n",
              "      <th>Occupation</th>\n",
              "      <th>Channel_Code</th>\n",
              "      <th>Vintage</th>\n",
              "      <th>Credit_Product</th>\n",
              "      <th>Avg_Account_Balance</th>\n",
              "      <th>Is_Active</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>105312.000000</td>\n",
              "      <td>105312.000000</td>\n",
              "      <td>105312.000000</td>\n",
              "      <td>105312.000000</td>\n",
              "      <td>105312.000000</td>\n",
              "      <td>105312.000000</td>\n",
              "      <td>105312.000000</td>\n",
              "      <td>105312.000000</td>\n",
              "      <td>105312.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>1.547943</td>\n",
              "      <td>0.336629</td>\n",
              "      <td>0.583224</td>\n",
              "      <td>3.103587</td>\n",
              "      <td>1.900781</td>\n",
              "      <td>0.311272</td>\n",
              "      <td>1.533899</td>\n",
              "      <td>0.107771</td>\n",
              "      <td>1.394210</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>0.497698</td>\n",
              "      <td>0.239885</td>\n",
              "      <td>0.320699</td>\n",
              "      <td>0.852286</td>\n",
              "      <td>0.883744</td>\n",
              "      <td>0.252138</td>\n",
              "      <td>0.697612</td>\n",
              "      <td>0.083847</td>\n",
              "      <td>0.488683</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.016129</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000175</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20%</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.096774</td>\n",
              "      <td>0.205882</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.093750</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.051239</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40%</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.209677</td>\n",
              "      <td>0.529412</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.156250</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.072470</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>2.000000</td>\n",
              "      <td>0.322581</td>\n",
              "      <td>0.558824</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>0.195312</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.084776</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>60%</th>\n",
              "      <td>2.000000</td>\n",
              "      <td>0.387097</td>\n",
              "      <td>0.705882</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>0.296875</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>0.099514</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>80%</th>\n",
              "      <td>2.000000</td>\n",
              "      <td>0.532258</td>\n",
              "      <td>0.941176</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>0.578125</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>0.146253</td>\n",
              "      <td>2.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>90%</th>\n",
              "      <td>2.000000</td>\n",
              "      <td>0.677419</td>\n",
              "      <td>0.970588</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>0.710938</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>0.197100</td>\n",
              "      <td>2.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>95%</th>\n",
              "      <td>2.000000</td>\n",
              "      <td>0.806452</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>0.796875</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>0.259291</td>\n",
              "      <td>2.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99%</th>\n",
              "      <td>2.000000</td>\n",
              "      <td>0.951613</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>0.906250</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>0.443345</td>\n",
              "      <td>2.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>2.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>0.957106</td>\n",
              "      <td>2.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              Gender            Age    Region_Code     Occupation   Channel_Code        Vintage  Credit_Product  Avg_Account_Balance      Is_Active\n",
              "count  105312.000000  105312.000000  105312.000000  105312.000000  105312.000000  105312.000000   105312.000000        105312.000000  105312.000000\n",
              "mean        1.547943       0.336629       0.583224       3.103587       1.900781       0.311272        1.533899             0.107771       1.394210\n",
              "std         0.497698       0.239885       0.320699       0.852286       0.883744       0.252138        0.697612             0.083847       0.488683\n",
              "min         1.000000       0.016129       0.000000       1.000000       1.000000       0.000000        1.000000             0.000175       1.000000\n",
              "20%         1.000000       0.096774       0.205882       2.000000       1.000000       0.093750        1.000000             0.051239       1.000000\n",
              "40%         1.000000       0.209677       0.529412       3.000000       1.000000       0.156250        1.000000             0.072470       1.000000\n",
              "50%         2.000000       0.322581       0.558824       3.000000       2.000000       0.195312        1.000000             0.084776       1.000000\n",
              "60%         2.000000       0.387097       0.705882       4.000000       2.000000       0.296875        2.000000             0.099514       1.000000\n",
              "80%         2.000000       0.532258       0.941176       4.000000       3.000000       0.578125        2.000000             0.146253       2.000000\n",
              "90%         2.000000       0.677419       0.970588       4.000000       3.000000       0.710938        3.000000             0.197100       2.000000\n",
              "95%         2.000000       0.806452       1.000000       4.000000       3.000000       0.796875        3.000000             0.259291       2.000000\n",
              "99%         2.000000       0.951613       1.000000       4.000000       4.000000       0.906250        3.000000             0.443345       2.000000\n",
              "max         2.000000       1.000000       1.000000       4.000000       4.000000       1.000000        3.000000             0.957106       2.000000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 201
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DAnL6kVuf5NS"
      },
      "source": [
        "# df_test.Credit_Product.value_counts()\n",
        "# X_train_norm['Credit_Product'] = X_train_norm['Credit_Product'].fillna(X_train_norm['Credit_Product'].mode()[0])\n",
        "# X_test_norm['Credit_Product'] = X_test_norm['Credit_Product'].fillna(X_test_norm['Credit_Product'].mode()[0])\n",
        "X_train_norm['Credit_Product'].fillna(4,inplace=True)\n",
        "X_test_norm['Credit_Product'].fillna(4,inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Feh-_t3IIVbP"
      },
      "source": [
        "X=X_train_norm.drop(['Is_Lead','ID'],axis=1)\n",
        "y=X_train_norm[['Is_Lead']]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qxahDeBqH-ko",
        "outputId": "e2dcb2f4-9016-4924-9f15-1623053f2aaa"
      },
      "source": [
        "oversample = SMOTE()\n",
        "# oversample=RandomUnderSampler()\n",
        "X, y = oversample.fit_resample(X, y)\n",
        "neg,pos=X_train_norm[['Is_Lead']].value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning:\n",
            "\n",
            "Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0sWEyGfNLF8J"
      },
      "source": [
        "X=pd.DataFrame(X)\n",
        "y=pd.DataFrame(y)\n",
        "train_x, valid_x, train_y, valid_y = train_test_split(X, y, test_size=0.25,stratify=y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lKQVo5Tc_NQP",
        "outputId": "1ed1ec20-4a68-466d-f059-da9c4d1aa2e1"
      },
      "source": [
        "\n",
        "clf=RandomForestClassifier(n_estimators=50)\n",
        "clf.fit(train_x,train_y)\n",
        "y_pred=clf.predict(train_x)\n",
        "y_pred_valid=clf.predict(valid_x)\n",
        "print(sklearn.metrics.roc_auc_score(train_y, y_pred))\n",
        "print(sklearn.metrics.classification_report(train_y, y_pred))\n",
        "print(sklearn.metrics.roc_auc_score(valid_y, y_pred_valid))\n",
        "print(sklearn.metrics.classification_report(valid_y, y_pred_valid))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "0.9984174460966492\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00     93718\n",
            "           1       1.00      1.00      1.00     29144\n",
            "\n",
            "    accuracy                           1.00    122862\n",
            "   macro avg       1.00      1.00      1.00    122862\n",
            "weighted avg       1.00      1.00      1.00    122862\n",
            "\n",
            "0.755630076519884\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      0.94      0.91     93719\n",
            "           1       0.75      0.57      0.65     29144\n",
            "\n",
            "    accuracy                           0.85    122863\n",
            "   macro avg       0.81      0.76      0.78    122863\n",
            "weighted avg       0.85      0.85      0.85    122863\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SjdPpS9VD5s8",
        "outputId": "39b95fee-20f2-44b5-8190-ecc6cacec143"
      },
      "source": [
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "MLPC = MLPClassifier(hidden_layer_sizes=(200,), max_iter=10000)\n",
        "MLPC.fit(train_x, train_y)\n",
        "y_pred=MLPC.predict(train_x)\n",
        "y_pred_valid=MLPC.predict(valid_x)\n",
        "print(sklearn.metrics.roc_auc_score(train_y, y_pred))\n",
        "print(sklearn.metrics.classification_report(train_y, y_pred))\n",
        "print(sklearn.metrics.roc_auc_score(valid_y, y_pred_valid))\n",
        "print(sklearn.metrics.classification_report(valid_y, y_pred_valid))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:934: DataConversionWarning:\n",
            "\n",
            "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "0.753359483971682\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      0.96      0.91     93718\n",
            "           1       0.80      0.55      0.65     29144\n",
            "\n",
            "    accuracy                           0.86    122862\n",
            "   macro avg       0.84      0.75      0.78    122862\n",
            "weighted avg       0.85      0.86      0.85    122862\n",
            "\n",
            "0.7536823471014884\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      0.95      0.91     93719\n",
            "           1       0.79      0.55      0.65     29144\n",
            "\n",
            "    accuracy                           0.86    122863\n",
            "   macro avg       0.83      0.75      0.78    122863\n",
            "weighted avg       0.85      0.86      0.85    122863\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "99uSYDRKIu2F",
        "outputId": "9806195f-6ee6-4dea-b560-715ad12fda13"
      },
      "source": [
        "train_x.shape[1]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "9"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "IPX5w2U5ICin",
        "outputId": "cdd9236a-5c5b-42fc-805b-b2933b1f2148"
      },
      "source": [
        "import tensorflow as tf\n",
        "from sklearn import preprocessing\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization, LSTM\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score, f1_score, precision_recall_curve, auc\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras import optimizers\n",
        "model = Sequential()\n",
        "model.add(Dense(1024, input_shape = (train_x.shape[1],), activation = 'relu'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(512, activation = 'relu'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(256, activation = 'relu'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(128, activation = 'relu'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(64, activation = 'relu'))\n",
        "model.add(Dense(32, activation = 'relu'))\n",
        "model.add(Dense(16, activation = 'relu'))\n",
        "model.add(Dense(8, activation = 'relu'))\n",
        "model.add(Dense(1, activation = 'sigmoid'))\n",
        "sgd = optimizers.Adam(lr = 0.001)\n",
        "model.compile(optimizer = sgd, loss = 'binary_crossentropy', metrics=[tf.keras.metrics.AUC()])\n",
        "model.fit(train_x, train_y.values, batch_size =128, epochs =100, verbose = 1)\n",
        "best_model=model\n",
        "new_preds = best_model.predict(train_x)\n",
        "new_pred_labels = np.rint(new_preds)\n",
        "print(sklearn.metrics.roc_auc_score(train_y, new_pred_labels))\n",
        "print(sklearn.metrics.classification_report(train_y, new_pred_labels))\n",
        "new_preds = best_model.predict(valid_x)\n",
        "new_pred_labels = np.rint(new_preds)\n",
        "print(sklearn.metrics.roc_auc_score(valid_y, new_pred_labels))\n",
        "print(sklearn.metrics.classification_report(valid_y, new_pred_labels))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:375: UserWarning:\n",
            "\n",
            "The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "2197/2197 [==============================] - 56s 25ms/step - loss: 0.4753 - auc_29: 0.8513\n",
            "Epoch 2/100\n",
            "2197/2197 [==============================] - 55s 25ms/step - loss: 0.4612 - auc_29: 0.8600\n",
            "Epoch 3/100\n",
            "2197/2197 [==============================] - 55s 25ms/step - loss: 0.4555 - auc_29: 0.8634\n",
            "Epoch 4/100\n",
            "2197/2197 [==============================] - 54s 25ms/step - loss: 0.4512 - auc_29: 0.8654\n",
            "Epoch 5/100\n",
            "2197/2197 [==============================] - 55s 25ms/step - loss: 0.4469 - auc_29: 0.8675\n",
            "Epoch 6/100\n",
            "2197/2197 [==============================] - 54s 25ms/step - loss: 0.4455 - auc_29: 0.8682\n",
            "Epoch 7/100\n",
            "2197/2197 [==============================] - 54s 25ms/step - loss: 0.4441 - auc_29: 0.8691\n",
            "Epoch 8/100\n",
            "2197/2197 [==============================] - 55s 25ms/step - loss: 0.4430 - auc_29: 0.8695\n",
            "Epoch 9/100\n",
            "2197/2197 [==============================] - 55s 25ms/step - loss: 0.4426 - auc_29: 0.8696\n",
            "Epoch 10/100\n",
            "2197/2197 [==============================] - 54s 25ms/step - loss: 0.4425 - auc_29: 0.8698\n",
            "Epoch 11/100\n",
            "2197/2197 [==============================] - 58s 26ms/step - loss: 0.4422 - auc_29: 0.8700\n",
            "Epoch 12/100\n",
            "2197/2197 [==============================] - 54s 25ms/step - loss: 0.4414 - auc_29: 0.8703\n",
            "Epoch 13/100\n",
            "2197/2197 [==============================] - 54s 25ms/step - loss: 0.4412 - auc_29: 0.8705\n",
            "Epoch 14/100\n",
            "2197/2197 [==============================] - 54s 25ms/step - loss: 0.4410 - auc_29: 0.8708\n",
            "Epoch 15/100\n",
            "2197/2197 [==============================] - 54s 25ms/step - loss: 0.4405 - auc_29: 0.8710\n",
            "Epoch 16/100\n",
            "2197/2197 [==============================] - 53s 24ms/step - loss: 0.4408 - auc_29: 0.8707\n",
            "Epoch 17/100\n",
            "2197/2197 [==============================] - 54s 25ms/step - loss: 0.4403 - auc_29: 0.8712\n",
            "Epoch 18/100\n",
            "2197/2197 [==============================] - 53s 24ms/step - loss: 0.4403 - auc_29: 0.8714\n",
            "Epoch 19/100\n",
            "2197/2197 [==============================] - 54s 24ms/step - loss: 0.4399 - auc_29: 0.8715\n",
            "Epoch 20/100\n",
            "2197/2197 [==============================] - 54s 24ms/step - loss: 0.4398 - auc_29: 0.8717\n",
            "Epoch 21/100\n",
            "2197/2197 [==============================] - 53s 24ms/step - loss: 0.4400 - auc_29: 0.8713\n",
            "Epoch 22/100\n",
            "2197/2197 [==============================] - 53s 24ms/step - loss: 0.4395 - auc_29: 0.8718\n",
            "Epoch 23/100\n",
            "2197/2197 [==============================] - 59s 27ms/step - loss: 0.4402 - auc_29: 0.8712\n",
            "Epoch 24/100\n",
            "2197/2197 [==============================] - 53s 24ms/step - loss: 0.4400 - auc_29: 0.8715\n",
            "Epoch 25/100\n",
            "2197/2197 [==============================] - 53s 24ms/step - loss: 0.4395 - auc_29: 0.8718\n",
            "Epoch 26/100\n",
            "2197/2197 [==============================] - 54s 24ms/step - loss: 0.4392 - auc_29: 0.8719\n",
            "Epoch 27/100\n",
            "2197/2197 [==============================] - 53s 24ms/step - loss: 0.4394 - auc_29: 0.8719\n",
            "Epoch 28/100\n",
            "2197/2197 [==============================] - 54s 24ms/step - loss: 0.4391 - auc_29: 0.8721\n",
            "Epoch 29/100\n",
            "2197/2197 [==============================] - 53s 24ms/step - loss: 0.4400 - auc_29: 0.8716\n",
            "Epoch 30/100\n",
            "2197/2197 [==============================] - 54s 24ms/step - loss: 0.4386 - auc_29: 0.8724\n",
            "Epoch 31/100\n",
            "2197/2197 [==============================] - 54s 25ms/step - loss: 0.4392 - auc_29: 0.8721\n",
            "Epoch 32/100\n",
            "2197/2197 [==============================] - 54s 24ms/step - loss: 0.4385 - auc_29: 0.8722\n",
            "Epoch 33/100\n",
            "2197/2197 [==============================] - 54s 24ms/step - loss: 0.4386 - auc_29: 0.8724\n",
            "Epoch 34/100\n",
            "2197/2197 [==============================] - 53s 24ms/step - loss: 0.4387 - auc_29: 0.8723\n",
            "Epoch 35/100\n",
            "2197/2197 [==============================] - 55s 25ms/step - loss: 0.4387 - auc_29: 0.8726\n",
            "Epoch 36/100\n",
            "2197/2197 [==============================] - 55s 25ms/step - loss: 0.4387 - auc_29: 0.8724\n",
            "Epoch 37/100\n",
            "2197/2197 [==============================] - 55s 25ms/step - loss: 0.4380 - auc_29: 0.8728\n",
            "Epoch 38/100\n",
            "2197/2197 [==============================] - 55s 25ms/step - loss: 0.4385 - auc_29: 0.8726\n",
            "Epoch 39/100\n",
            "2197/2197 [==============================] - 55s 25ms/step - loss: 0.4386 - auc_29: 0.8726\n",
            "Epoch 40/100\n",
            "2197/2197 [==============================] - 55s 25ms/step - loss: 0.4380 - auc_29: 0.8730\n",
            "Epoch 41/100\n",
            "2197/2197 [==============================] - 55s 25ms/step - loss: 0.4384 - auc_29: 0.8728\n",
            "Epoch 42/100\n",
            "2197/2197 [==============================] - 55s 25ms/step - loss: 0.4388 - auc_29: 0.8726\n",
            "Epoch 43/100\n",
            "2197/2197 [==============================] - 55s 25ms/step - loss: 0.4383 - auc_29: 0.8732\n",
            "Epoch 44/100\n",
            "2197/2197 [==============================] - 55s 25ms/step - loss: 0.4382 - auc_29: 0.8728\n",
            "Epoch 45/100\n",
            "2197/2197 [==============================] - 55s 25ms/step - loss: 0.4383 - auc_29: 0.8728\n",
            "Epoch 46/100\n",
            "2197/2197 [==============================] - 55s 25ms/step - loss: 0.4379 - auc_29: 0.8731\n",
            "Epoch 47/100\n",
            "2197/2197 [==============================] - 55s 25ms/step - loss: 0.4379 - auc_29: 0.8729\n",
            "Epoch 48/100\n",
            "2197/2197 [==============================] - 55s 25ms/step - loss: 0.4379 - auc_29: 0.8732\n",
            "Epoch 49/100\n",
            "2197/2197 [==============================] - 55s 25ms/step - loss: 0.4383 - auc_29: 0.8727\n",
            "Epoch 50/100\n",
            "2197/2197 [==============================] - 55s 25ms/step - loss: 0.4378 - auc_29: 0.8732\n",
            "Epoch 51/100\n",
            "2197/2197 [==============================] - 55s 25ms/step - loss: 0.4383 - auc_29: 0.8730\n",
            "Epoch 52/100\n",
            "2197/2197 [==============================] - 56s 25ms/step - loss: 0.4376 - auc_29: 0.8733\n",
            "Epoch 53/100\n",
            "2197/2197 [==============================] - 55s 25ms/step - loss: 0.4375 - auc_29: 0.8733\n",
            "Epoch 54/100\n",
            "2197/2197 [==============================] - 55s 25ms/step - loss: 0.4373 - auc_29: 0.8737\n",
            "Epoch 55/100\n",
            "2197/2197 [==============================] - 55s 25ms/step - loss: 0.4370 - auc_29: 0.8739\n",
            "Epoch 56/100\n",
            "2197/2197 [==============================] - 55s 25ms/step - loss: 0.4377 - auc_29: 0.8733\n",
            "Epoch 57/100\n",
            "2197/2197 [==============================] - 55s 25ms/step - loss: 0.4375 - auc_29: 0.8736\n",
            "Epoch 58/100\n",
            "1508/2197 [===================>..........] - ETA: 17s - loss: 0.4375 - auc_29: 0.8733"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-249-33594c6ca69f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0msgd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimizers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.001\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msgd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'binary_crossentropy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAUC\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0mbest_model\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0mnew_preds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbest_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1181\u001b[0m                 _r=1):\n\u001b[1;32m   1182\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1183\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1184\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1185\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    887\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    915\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    916\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 917\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    918\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3022\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   3023\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 3024\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   3025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3026\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1959\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1960\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1961\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1962\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1963\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    594\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    595\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 596\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    597\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GjzlK09-S8v8",
        "outputId": "970e0aee-6c06-4f83-ebd0-81c9d1d83d67"
      },
      "source": [
        "X_test_norm1=X_test_norm.drop(['ID'],axis=1)\n",
        "test_preds = np.rint(best_model.predict(X_test_norm1))\n",
        "test_pred=pd.DataFrame(test_preds)\n",
        "test_pred.value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0    73012\n",
              "1.0    32300\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 235
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QvDBjDJZJMD0"
      },
      "source": [
        "\n",
        "dtrain = lgb.Dataset(train_x, label=train_y)\n",
        "dvalid = lgb.Dataset(valid_x, label=valid_y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0mpuTkBdK-4z"
      },
      "source": [
        "class Objective:\n",
        "\n",
        "    def __init__(self):\n",
        "        self.best_booster = None\n",
        "        self._booster = None\n",
        "\n",
        "    def __call__(self, trial):\n",
        "        param = {\n",
        "            \"objective\": \"binary\",\n",
        "            \"metric\": \"auc\",\n",
        "            \"verbosity\": -1,\n",
        "            \"boosting_type\": \"gbdt\",\n",
        "            \"bagging_fraction\": trial.suggest_loguniform(\"bagging_fraction\", 0.01, 1.0),\n",
        "            # \"feature_fraction\": trial.suggest_loguniform(\"feature_fraction\", 0.01, 1.0),\n",
        "            \"min_gain_to_split\": trial.suggest_loguniform(\"min_gain_to_split\", 0.01, 1.0),\n",
        "            \"max_depth\": -1,\n",
        "            \"lambda_l1\": trial.suggest_loguniform(\"lambda_l1\", 1e-8, 10.0),\n",
        "            \"lambda_l2\": trial.suggest_loguniform(\"lambda_l2\", 1e-8, 10.0),\n",
        "            \"num_leaves\": trial.suggest_int(\"num_leaves\", 2, 200),\n",
        "            \"num_iterations\": trial.suggest_int(\"num_iterations\", 20, 1000),\n",
        "            \"early_stopping_rounds\": trial.suggest_int(\"early_stopping_rounds\", 20, 100),\n",
        "            \"learning_rate\":trial.suggest_loguniform(\"learning_rate\", 0.01, 1.0),\n",
        "            \"n_estimators\": trial.suggest_int(\"n_estimators\", 10, 1000)\n",
        "            ,\n",
        "            \"scale_pos_weight\" : train_y.size/train_y.where(train_y==0).dropna().size-1\n",
        "        }\n",
        "\n",
        "        # Add a callback for pruning.\n",
        "        pruning_callback = optuna.integration.LightGBMPruningCallback(trial, \"auc\")\n",
        "        gbm = lgb.train(\n",
        "            param, dtrain, valid_sets=[dvalid], verbose_eval=False, callbacks=[pruning_callback]\n",
        "        )\n",
        "\n",
        "        self._booster = gbm\n",
        "\n",
        "        preds = gbm.predict(valid_x)\n",
        "        pred_labels = np.rint(preds)\n",
        "        accuracy = sklearn.metrics.accuracy_score(valid_y, pred_labels)\n",
        "        return accuracy\n",
        "\n",
        "    def callback(self, study, trial):\n",
        "        if study.best_trial == trial:\n",
        "            self.best_booster = self._booster"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CjVCzIVGM59s",
        "outputId": "9b20057f-bd6c-4160-b53e-b4743a2a4a5d"
      },
      "source": [
        "objective = Objective()\n",
        "\n",
        "study = optuna.create_study(\n",
        "    pruner=optuna.pruners.MedianPruner(n_warmup_steps=10), direction=\"maximize\"\n",
        ")\n",
        "study.optimize(objective, n_trials=100, callbacks=[objective.callback])\n",
        "\n",
        "print(\"Best trial:\")\n",
        "trial = study.best_trial\n",
        "\n",
        "print(\"  Params: \")\n",
        "for key, value in trial.params.items():\n",
        "    print(\"    {}: {}\".format(key, value))\n",
        "\n",
        "best_model = objective.best_booster\n",
        "\n",
        "new_preds = best_model.predict(train_x)\n",
        "new_pred_labels = np.rint(new_preds)\n",
        "print(sklearn.metrics.roc_auc_score(train_y, new_pred_labels))\n",
        "print(sklearn.metrics.classification_report(train_y, new_pred_labels))\n",
        "new_preds = best_model.predict(valid_x)\n",
        "new_pred_labels = np.rint(new_preds)\n",
        "print(sklearn.metrics.roc_auc_score(valid_y, new_pred_labels))\n",
        "print(sklearn.metrics.classification_report(valid_y, new_pred_labels))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-05-30 06:50:51,760]\u001b[0m A new study created in memory with name: no-name-e6b974d4-775a-4979-9cc9-7a462087a7be\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/lightgbm/engine.py:118: UserWarning:\n",
            "\n",
            "Found `num_iterations` in params. Will use it instead of argument\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/lightgbm/engine.py:123: UserWarning:\n",
            "\n",
            "Found `early_stopping_rounds` in params. Will use it instead of argument\n",
            "\n",
            "\u001b[32m[I 2021-05-30 06:50:55,044]\u001b[0m Trial 0 finished with value: 0.8556685088269048 and parameters: {'bagging_fraction': 0.10630042644762501, 'min_gain_to_split': 0.029965254842991732, 'lambda_l1': 0.20823790314129825, 'lambda_l2': 0.0007619274172190505, 'num_leaves': 26, 'num_iterations': 283, 'early_stopping_rounds': 90, 'learning_rate': 0.23895909999845208, 'n_estimators': 845}. Best is trial 0 with value: 0.8556685088269048.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/lightgbm/engine.py:118: UserWarning:\n",
            "\n",
            "Found `num_iterations` in params. Will use it instead of argument\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/lightgbm/engine.py:123: UserWarning:\n",
            "\n",
            "Found `early_stopping_rounds` in params. Will use it instead of argument\n",
            "\n",
            "\u001b[32m[I 2021-05-30 06:50:58,593]\u001b[0m Trial 1 finished with value: 0.855880126645125 and parameters: {'bagging_fraction': 0.44353530912582756, 'min_gain_to_split': 0.4274071270722828, 'lambda_l1': 9.606914508959501e-08, 'lambda_l2': 9.529398209096122e-05, 'num_leaves': 141, 'num_iterations': 97, 'early_stopping_rounds': 35, 'learning_rate': 0.060083219507835725, 'n_estimators': 893}. Best is trial 1 with value: 0.855880126645125.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/lightgbm/engine.py:118: UserWarning:\n",
            "\n",
            "Found `num_iterations` in params. Will use it instead of argument\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/lightgbm/engine.py:123: UserWarning:\n",
            "\n",
            "Found `early_stopping_rounds` in params. Will use it instead of argument\n",
            "\n",
            "\u001b[32m[I 2021-05-30 06:51:05,238]\u001b[0m Trial 2 finished with value: 0.8560103529947991 and parameters: {'bagging_fraction': 0.04202888071413092, 'min_gain_to_split': 0.26700719069527573, 'lambda_l1': 7.340200404122137e-06, 'lambda_l2': 0.013008422080704343, 'num_leaves': 126, 'num_iterations': 388, 'early_stopping_rounds': 71, 'learning_rate': 0.032171521261077925, 'n_estimators': 546}. Best is trial 2 with value: 0.8560103529947991.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/lightgbm/engine.py:118: UserWarning:\n",
            "\n",
            "Found `num_iterations` in params. Will use it instead of argument\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/lightgbm/engine.py:123: UserWarning:\n",
            "\n",
            "Found `early_stopping_rounds` in params. Will use it instead of argument\n",
            "\n",
            "\u001b[32m[I 2021-05-30 06:51:06,595]\u001b[0m Trial 3 finished with value: 0.8528767814557678 and parameters: {'bagging_fraction': 0.016183632625330843, 'min_gain_to_split': 0.1435275558949595, 'lambda_l1': 0.00662851878878374, 'lambda_l2': 0.40260027970136647, 'num_leaves': 186, 'num_iterations': 958, 'early_stopping_rounds': 30, 'learning_rate': 0.2893636399785377, 'n_estimators': 999}. Best is trial 2 with value: 0.8560103529947991.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/lightgbm/engine.py:118: UserWarning:\n",
            "\n",
            "Found `num_iterations` in params. Will use it instead of argument\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/lightgbm/engine.py:123: UserWarning:\n",
            "\n",
            "Found `early_stopping_rounds` in params. Will use it instead of argument\n",
            "\n",
            "\u001b[32m[I 2021-05-30 06:51:09,170]\u001b[0m Trial 4 finished with value: 0.8403099387122241 and parameters: {'bagging_fraction': 0.013419138011337919, 'min_gain_to_split': 0.2956189758341884, 'lambda_l1': 3.4983446638884737e-07, 'lambda_l2': 0.02589091722680301, 'num_leaves': 145, 'num_iterations': 610, 'early_stopping_rounds': 89, 'learning_rate': 0.9797756395809283, 'n_estimators': 413}. Best is trial 2 with value: 0.8560103529947991.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/lightgbm/engine.py:118: UserWarning:\n",
            "\n",
            "Found `num_iterations` in params. Will use it instead of argument\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/lightgbm/engine.py:123: UserWarning:\n",
            "\n",
            "Found `early_stopping_rounds` in params. Will use it instead of argument\n",
            "\n",
            "\u001b[32m[I 2021-05-30 06:51:10,177]\u001b[0m Trial 5 finished with value: 0.8543092713021821 and parameters: {'bagging_fraction': 0.010411354087277044, 'min_gain_to_split': 0.06082540992417842, 'lambda_l1': 0.38446788195526543, 'lambda_l2': 1.3066054055524186, 'num_leaves': 40, 'num_iterations': 792, 'early_stopping_rounds': 26, 'learning_rate': 0.561251705994798, 'n_estimators': 560}. Best is trial 2 with value: 0.8560103529947991.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/lightgbm/engine.py:118: UserWarning:\n",
            "\n",
            "Found `num_iterations` in params. Will use it instead of argument\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/lightgbm/engine.py:123: UserWarning:\n",
            "\n",
            "Found `early_stopping_rounds` in params. Will use it instead of argument\n",
            "\n",
            "\u001b[32m[I 2021-05-30 06:51:10,471]\u001b[0m Trial 6 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/lightgbm/engine.py:118: UserWarning:\n",
            "\n",
            "Found `num_iterations` in params. Will use it instead of argument\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/lightgbm/engine.py:123: UserWarning:\n",
            "\n",
            "Found `early_stopping_rounds` in params. Will use it instead of argument\n",
            "\n",
            "\u001b[32m[I 2021-05-30 06:51:10,814]\u001b[0m Trial 7 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/lightgbm/engine.py:118: UserWarning:\n",
            "\n",
            "Found `num_iterations` in params. Will use it instead of argument\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/lightgbm/engine.py:123: UserWarning:\n",
            "\n",
            "Found `early_stopping_rounds` in params. Will use it instead of argument\n",
            "\n",
            "\u001b[32m[I 2021-05-30 06:51:11,035]\u001b[0m Trial 8 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/lightgbm/engine.py:118: UserWarning:\n",
            "\n",
            "Found `num_iterations` in params. Will use it instead of argument\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/lightgbm/engine.py:123: UserWarning:\n",
            "\n",
            "Found `early_stopping_rounds` in params. Will use it instead of argument\n",
            "\n",
            "\u001b[32m[I 2021-05-30 06:51:11,478]\u001b[0m Trial 9 pruned. Trial was pruned at iteration 12.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/lightgbm/engine.py:118: UserWarning:\n",
            "\n",
            "Found `num_iterations` in params. Will use it instead of argument\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/lightgbm/engine.py:123: UserWarning:\n",
            "\n",
            "Found `early_stopping_rounds` in params. Will use it instead of argument\n",
            "\n",
            "\u001b[32m[I 2021-05-30 06:51:11,805]\u001b[0m Trial 10 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/lightgbm/engine.py:118: UserWarning:\n",
            "\n",
            "Found `num_iterations` in params. Will use it instead of argument\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/lightgbm/engine.py:123: UserWarning:\n",
            "\n",
            "Found `early_stopping_rounds` in params. Will use it instead of argument\n",
            "\n",
            "\u001b[32m[I 2021-05-30 06:51:12,185]\u001b[0m Trial 11 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/lightgbm/engine.py:118: UserWarning:\n",
            "\n",
            "Found `num_iterations` in params. Will use it instead of argument\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/lightgbm/engine.py:123: UserWarning:\n",
            "\n",
            "Found `early_stopping_rounds` in params. Will use it instead of argument\n",
            "\n",
            "\u001b[32m[I 2021-05-30 06:51:12,547]\u001b[0m Trial 12 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/lightgbm/engine.py:118: UserWarning:\n",
            "\n",
            "Found `num_iterations` in params. Will use it instead of argument\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/lightgbm/engine.py:123: UserWarning:\n",
            "\n",
            "Found `early_stopping_rounds` in params. Will use it instead of argument\n",
            "\n",
            "\u001b[32m[I 2021-05-30 06:51:12,914]\u001b[0m Trial 13 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/lightgbm/engine.py:118: UserWarning:\n",
            "\n",
            "Found `num_iterations` in params. Will use it instead of argument\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/lightgbm/engine.py:123: UserWarning:\n",
            "\n",
            "Found `early_stopping_rounds` in params. Will use it instead of argument\n",
            "\n",
            "\u001b[32m[I 2021-05-30 06:51:13,327]\u001b[0m Trial 14 pruned. Trial was pruned at iteration 11.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/lightgbm/engine.py:118: UserWarning:\n",
            "\n",
            "Found `num_iterations` in params. Will use it instead of argument\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/lightgbm/engine.py:123: UserWarning:\n",
            "\n",
            "Found `early_stopping_rounds` in params. Will use it instead of argument\n",
            "\n",
            "\u001b[32m[I 2021-05-30 06:51:13,753]\u001b[0m Trial 15 pruned. Trial was pruned at iteration 13.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/lightgbm/engine.py:118: UserWarning:\n",
            "\n",
            "Found `num_iterations` in params. Will use it instead of argument\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/lightgbm/engine.py:123: UserWarning:\n",
            "\n",
            "Found `early_stopping_rounds` in params. Will use it instead of argument\n",
            "\n",
            "\u001b[32m[I 2021-05-30 06:51:14,038]\u001b[0m Trial 16 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/lightgbm/engine.py:118: UserWarning:\n",
            "\n",
            "Found `num_iterations` in params. Will use it instead of argument\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/lightgbm/engine.py:123: UserWarning:\n",
            "\n",
            "Found `early_stopping_rounds` in params. Will use it instead of argument\n",
            "\n",
            "\u001b[32m[I 2021-05-30 06:51:14,433]\u001b[0m Trial 17 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/lightgbm/engine.py:118: UserWarning:\n",
            "\n",
            "Found `num_iterations` in params. Will use it instead of argument\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/lightgbm/engine.py:123: UserWarning:\n",
            "\n",
            "Found `early_stopping_rounds` in params. Will use it instead of argument\n",
            "\n",
            "\u001b[32m[I 2021-05-30 06:51:14,857]\u001b[0m Trial 18 pruned. Trial was pruned at iteration 11.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/lightgbm/engine.py:118: UserWarning:\n",
            "\n",
            "Found `num_iterations` in params. Will use it instead of argument\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/lightgbm/engine.py:123: UserWarning:\n",
            "\n",
            "Found `early_stopping_rounds` in params. Will use it instead of argument\n",
            "\n",
            "\u001b[32m[I 2021-05-30 06:51:16,585]\u001b[0m Trial 19 finished with value: 0.8551476034282086 and parameters: {'bagging_fraction': 0.01898358323095035, 'min_gain_to_split': 0.567893357160592, 'lambda_l1': 6.710192498129556e-07, 'lambda_l2': 1.6589715519123895e-06, 'num_leaves': 104, 'num_iterations': 730, 'early_stopping_rounds': 20, 'learning_rate': 0.1409219583412867, 'n_estimators': 479}. Best is trial 2 with value: 0.8560103529947991.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/lightgbm/engine.py:118: UserWarning:\n",
            "\n",
            "Found `num_iterations` in params. Will use it instead of argument\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/lightgbm/engine.py:123: UserWarning:\n",
            "\n",
            "Found `early_stopping_rounds` in params. Will use it instead of argument\n",
            "\n",
            "\u001b[32m[I 2021-05-30 06:51:16,949]\u001b[0m Trial 20 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/lightgbm/engine.py:118: UserWarning:\n",
            "\n",
            "Found `num_iterations` in params. Will use it instead of argument\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/lightgbm/engine.py:123: UserWarning:\n",
            "\n",
            "Found `early_stopping_rounds` in params. Will use it instead of argument\n",
            "\n",
            "\u001b[32m[I 2021-05-30 06:51:17,194]\u001b[0m Trial 21 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/lightgbm/engine.py:118: UserWarning:\n",
            "\n",
            "Found `num_iterations` in params. Will use it instead of argument\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/lightgbm/engine.py:123: UserWarning:\n",
            "\n",
            "Found `early_stopping_rounds` in params. Will use it instead of argument\n",
            "\n",
            "\u001b[32m[I 2021-05-30 06:51:19,957]\u001b[0m Trial 22 finished with value: 0.8565231192466406 and parameters: {'bagging_fraction': 0.12662479766833926, 'min_gain_to_split': 0.030464234692411756, 'lambda_l1': 2.239568718793956e-05, 'lambda_l2': 0.00023743417157968223, 'num_leaves': 35, 'num_iterations': 170, 'early_stopping_rounds': 84, 'learning_rate': 0.22805917008732526, 'n_estimators': 867}. Best is trial 22 with value: 0.8565231192466406.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/lightgbm/engine.py:118: UserWarning:\n",
            "\n",
            "Found `num_iterations` in params. Will use it instead of argument\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/lightgbm/engine.py:123: UserWarning:\n",
            "\n",
            "Found `early_stopping_rounds` in params. Will use it instead of argument\n",
            "\n",
            "\u001b[32m[I 2021-05-30 06:51:20,276]\u001b[0m Trial 23 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/lightgbm/engine.py:118: UserWarning:\n",
            "\n",
            "Found `num_iterations` in params. Will use it instead of argument\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/lightgbm/engine.py:123: UserWarning:\n",
            "\n",
            "Found `early_stopping_rounds` in params. Will use it instead of argument\n",
            "\n",
            "\u001b[32m[I 2021-05-30 06:51:20,705]\u001b[0m Trial 24 pruned. Trial was pruned at iteration 12.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/lightgbm/engine.py:118: UserWarning:\n",
            "\n",
            "Found `num_iterations` in params. Will use it instead of argument\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/lightgbm/engine.py:123: UserWarning:\n",
            "\n",
            "Found `early_stopping_rounds` in params. Will use it instead of argument\n",
            "\n",
            "\u001b[32m[I 2021-05-30 06:51:20,975]\u001b[0m Trial 25 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/lightgbm/engine.py:118: UserWarning:\n",
            "\n",
            "Found `num_iterations` in params. Will use it instead of argument\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/lightgbm/engine.py:123: UserWarning:\n",
            "\n",
            "Found `early_stopping_rounds` in params. Will use it instead of argument\n",
            "\n",
            "\u001b[32m[I 2021-05-30 06:51:21,536]\u001b[0m Trial 26 pruned. Trial was pruned at iteration 16.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/lightgbm/engine.py:118: UserWarning:\n",
            "\n",
            "Found `num_iterations` in params. Will use it instead of argument\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/lightgbm/engine.py:123: UserWarning:\n",
            "\n",
            "Found `early_stopping_rounds` in params. Will use it instead of argument\n",
            "\n",
            "\u001b[32m[I 2021-05-30 06:51:21,901]\u001b[0m Trial 27 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/lightgbm/engine.py:118: UserWarning:\n",
            "\n",
            "Found `num_iterations` in params. Will use it instead of argument\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/lightgbm/engine.py:123: UserWarning:\n",
            "\n",
            "Found `early_stopping_rounds` in params. Will use it instead of argument\n",
            "\n",
            "\u001b[32m[I 2021-05-30 06:51:22,303]\u001b[0m Trial 28 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/lightgbm/engine.py:118: UserWarning:\n",
            "\n",
            "Found `num_iterations` in params. Will use it instead of argument\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/lightgbm/engine.py:123: UserWarning:\n",
            "\n",
            "Found `early_stopping_rounds` in params. Will use it instead of argument\n",
            "\n",
            "\u001b[32m[I 2021-05-30 06:51:22,613]\u001b[0m Trial 29 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/lightgbm/engine.py:118: UserWarning:\n",
            "\n",
            "Found `num_iterations` in params. Will use it instead of argument\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/lightgbm/engine.py:123: UserWarning:\n",
            "\n",
            "Found `early_stopping_rounds` in params. Will use it instead of argument\n",
            "\n",
            "\u001b[32m[I 2021-05-30 06:51:22,961]\u001b[0m Trial 30 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/lightgbm/engine.py:118: UserWarning:\n",
            "\n",
            "Found `num_iterations` in params. Will use it instead of argument\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/lightgbm/engine.py:123: UserWarning:\n",
            "\n",
            "Found `early_stopping_rounds` in params. Will use it instead of argument\n",
            "\n",
            "\u001b[32m[I 2021-05-30 06:51:25,685]\u001b[0m Trial 31 finished with value: 0.8562382491067286 and parameters: {'bagging_fraction': 0.12679287122788171, 'min_gain_to_split': 0.018469651433815903, 'lambda_l1': 0.0025314838745727985, 'lambda_l2': 0.18978418447094594, 'num_leaves': 23, 'num_iterations': 353, 'early_stopping_rounds': 90, 'learning_rate': 0.35228362669155266, 'n_estimators': 855}. Best is trial 22 with value: 0.8565231192466406.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/lightgbm/engine.py:118: UserWarning:\n",
            "\n",
            "Found `num_iterations` in params. Will use it instead of argument\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/lightgbm/engine.py:123: UserWarning:\n",
            "\n",
            "Found `early_stopping_rounds` in params. Will use it instead of argument\n",
            "\n",
            "\u001b[32m[I 2021-05-30 06:51:26,580]\u001b[0m Trial 32 pruned. Trial was pruned at iteration 37.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/lightgbm/engine.py:118: UserWarning:\n",
            "\n",
            "Found `num_iterations` in params. Will use it instead of argument\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/lightgbm/engine.py:123: UserWarning:\n",
            "\n",
            "Found `early_stopping_rounds` in params. Will use it instead of argument\n",
            "\n",
            "\u001b[32m[I 2021-05-30 06:51:29,547]\u001b[0m Trial 33 finished with value: 0.8551964383093364 and parameters: {'bagging_fraction': 0.06796309900308646, 'min_gain_to_split': 0.016756289375646206, 'lambda_l1': 0.002057138847960042, 'lambda_l2': 6.872180552977258, 'num_leaves': 40, 'num_iterations': 305, 'early_stopping_rounds': 87, 'learning_rate': 0.3257619093692945, 'n_estimators': 995}. Best is trial 22 with value: 0.8565231192466406.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/lightgbm/engine.py:118: UserWarning:\n",
            "\n",
            "Found `num_iterations` in params. Will use it instead of argument\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/lightgbm/engine.py:123: UserWarning:\n",
            "\n",
            "Found `early_stopping_rounds` in params. Will use it instead of argument\n",
            "\n",
            "\u001b[32m[I 2021-05-30 06:51:31,847]\u001b[0m Trial 34 finished with value: 0.8544720542392746 and parameters: {'bagging_fraction': 0.09336157458467378, 'min_gain_to_split': 0.02307691587985641, 'lambda_l1': 0.0002891256468389459, 'lambda_l2': 0.1637573071196825, 'num_leaves': 20, 'num_iterations': 555, 'early_stopping_rounds': 92, 'learning_rate': 0.7156499004971876, 'n_estimators': 843}. Best is trial 22 with value: 0.8565231192466406.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/lightgbm/engine.py:118: UserWarning:\n",
            "\n",
            "Found `num_iterations` in params. Will use it instead of argument\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/lightgbm/engine.py:123: UserWarning:\n",
            "\n",
            "Found `early_stopping_rounds` in params. Will use it instead of argument\n",
            "\n",
            "\u001b[32m[I 2021-05-30 06:51:34,711]\u001b[0m Trial 35 finished with value: 0.8550662119596624 and parameters: {'bagging_fraction': 0.03726864851327837, 'min_gain_to_split': 0.010051478629976575, 'lambda_l1': 0.025630787456920347, 'lambda_l2': 1.1968192715046093, 'num_leaves': 38, 'num_iterations': 883, 'early_stopping_rounds': 100, 'learning_rate': 0.36734443988716214, 'n_estimators': 416}. Best is trial 22 with value: 0.8565231192466406.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/lightgbm/engine.py:118: UserWarning:\n",
            "\n",
            "Found `num_iterations` in params. Will use it instead of argument\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/lightgbm/engine.py:123: UserWarning:\n",
            "\n",
            "Found `early_stopping_rounds` in params. Will use it instead of argument\n",
            "\n",
            "\u001b[32m[I 2021-05-30 06:51:35,098]\u001b[0m Trial 36 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/lightgbm/engine.py:118: UserWarning:\n",
            "\n",
            "Found `num_iterations` in params. Will use it instead of argument\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/lightgbm/engine.py:123: UserWarning:\n",
            "\n",
            "Found `early_stopping_rounds` in params. Will use it instead of argument\n",
            "\n",
            "\u001b[32m[I 2021-05-30 06:51:35,494]\u001b[0m Trial 37 pruned. Trial was pruned at iteration 13.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/lightgbm/engine.py:118: UserWarning:\n",
            "\n",
            "Found `num_iterations` in params. Will use it instead of argument\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/lightgbm/engine.py:123: UserWarning:\n",
            "\n",
            "Found `early_stopping_rounds` in params. Will use it instead of argument\n",
            "\n",
            "\u001b[32m[I 2021-05-30 06:51:35,844]\u001b[0m Trial 38 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/lightgbm/engine.py:118: UserWarning:\n",
            "\n",
            "Found `num_iterations` in params. Will use it instead of argument\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/lightgbm/engine.py:123: UserWarning:\n",
            "\n",
            "Found `early_stopping_rounds` in params. Will use it instead of argument\n",
            "\n",
            "\u001b[32m[I 2021-05-30 06:51:36,740]\u001b[0m Trial 39 pruned. Trial was pruned at iteration 27.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/lightgbm/engine.py:118: UserWarning:\n",
            "\n",
            "Found `num_iterations` in params. Will use it instead of argument\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/lightgbm/engine.py:123: UserWarning:\n",
            "\n",
            "Found `early_stopping_rounds` in params. Will use it instead of argument\n",
            "\n",
            "\u001b[32m[I 2021-05-30 06:51:36,965]\u001b[0m Trial 40 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/lightgbm/engine.py:118: UserWarning:\n",
            "\n",
            "Found `num_iterations` in params. Will use it instead of argument\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/lightgbm/engine.py:123: UserWarning:\n",
            "\n",
            "Found `early_stopping_rounds` in params. Will use it instead of argument\n",
            "\n",
            "\u001b[32m[I 2021-05-30 06:51:39,592]\u001b[0m Trial 41 finished with value: 0.8537395310223582 and parameters: {'bagging_fraction': 0.17225106775528395, 'min_gain_to_split': 0.02995936913288934, 'lambda_l1': 1.7176342981341708, 'lambda_l2': 8.368192633780899e-05, 'num_leaves': 46, 'num_iterations': 191, 'early_stopping_rounds': 92, 'learning_rate': 0.4253626378137592, 'n_estimators': 843}. Best is trial 22 with value: 0.8565231192466406.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/lightgbm/engine.py:118: UserWarning:\n",
            "\n",
            "Found `num_iterations` in params. Will use it instead of argument\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/lightgbm/engine.py:123: UserWarning:\n",
            "\n",
            "Found `early_stopping_rounds` in params. Will use it instead of argument\n",
            "\n",
            "\u001b[32m[I 2021-05-30 06:51:39,899]\u001b[0m Trial 42 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/lightgbm/engine.py:118: UserWarning:\n",
            "\n",
            "Found `num_iterations` in params. Will use it instead of argument\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/lightgbm/engine.py:123: UserWarning:\n",
            "\n",
            "Found `early_stopping_rounds` in params. Will use it instead of argument\n",
            "\n",
            "\u001b[32m[I 2021-05-30 06:51:42,017]\u001b[0m Trial 43 finished with value: 0.8557580394423057 and parameters: {'bagging_fraction': 0.04483404878099743, 'min_gain_to_split': 0.02452127636353362, 'lambda_l1': 9.798153914633467, 'lambda_l2': 0.001075984476989069, 'num_leaves': 15, 'num_iterations': 378, 'early_stopping_rounds': 75, 'learning_rate': 0.5715287066000974, 'n_estimators': 766}. Best is trial 22 with value: 0.8565231192466406.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/lightgbm/engine.py:118: UserWarning:\n",
            "\n",
            "Found `num_iterations` in params. Will use it instead of argument\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/lightgbm/engine.py:123: UserWarning:\n",
            "\n",
            "Found `early_stopping_rounds` in params. Will use it instead of argument\n",
            "\n",
            "\u001b[32m[I 2021-05-30 06:51:42,364]\u001b[0m Trial 44 pruned. Trial was pruned at iteration 13.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/lightgbm/engine.py:118: UserWarning:\n",
            "\n",
            "Found `num_iterations` in params. Will use it instead of argument\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/lightgbm/engine.py:123: UserWarning:\n",
            "\n",
            "Found `early_stopping_rounds` in params. Will use it instead of argument\n",
            "\n",
            "\u001b[32m[I 2021-05-30 06:51:42,716]\u001b[0m Trial 45 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/lightgbm/engine.py:118: UserWarning:\n",
            "\n",
            "Found `num_iterations` in params. Will use it instead of argument\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/lightgbm/engine.py:123: UserWarning:\n",
            "\n",
            "Found `early_stopping_rounds` in params. Will use it instead of argument\n",
            "\n",
            "\u001b[32m[I 2021-05-30 06:51:44,320]\u001b[0m Trial 46 finished with value: 0.8543581061833099 and parameters: {'bagging_fraction': 0.026317110444343886, 'min_gain_to_split': 0.7555785945741448, 'lambda_l1': 2.1604794303051365, 'lambda_l2': 0.00016857968916254013, 'num_leaves': 29, 'num_iterations': 457, 'early_stopping_rounds': 70, 'learning_rate': 0.49798288971564664, 'n_estimators': 606}. Best is trial 22 with value: 0.8565231192466406.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/lightgbm/engine.py:118: UserWarning:\n",
            "\n",
            "Found `num_iterations` in params. Will use it instead of argument\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/lightgbm/engine.py:123: UserWarning:\n",
            "\n",
            "Found `early_stopping_rounds` in params. Will use it instead of argument\n",
            "\n",
            "\u001b[32m[I 2021-05-30 06:51:44,623]\u001b[0m Trial 47 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/lightgbm/engine.py:118: UserWarning:\n",
            "\n",
            "Found `num_iterations` in params. Will use it instead of argument\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/lightgbm/engine.py:123: UserWarning:\n",
            "\n",
            "Found `early_stopping_rounds` in params. Will use it instead of argument\n",
            "\n",
            "\u001b[32m[I 2021-05-30 06:51:44,994]\u001b[0m Trial 48 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/lightgbm/engine.py:118: UserWarning:\n",
            "\n",
            "Found `num_iterations` in params. Will use it instead of argument\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/lightgbm/engine.py:123: UserWarning:\n",
            "\n",
            "Found `early_stopping_rounds` in params. Will use it instead of argument\n",
            "\n",
            "\u001b[32m[I 2021-05-30 06:51:45,388]\u001b[0m Trial 49 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/lightgbm/engine.py:118: UserWarning:\n",
            "\n",
            "Found `num_iterations` in params. Will use it instead of argument\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/lightgbm/engine.py:123: UserWarning:\n",
            "\n",
            "Found `early_stopping_rounds` in params. Will use it instead of argument\n",
            "\n",
            "\u001b[32m[I 2021-05-30 06:51:45,662]\u001b[0m Trial 50 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/lightgbm/engine.py:118: UserWarning:\n",
            "\n",
            "Found `num_iterations` in params. Will use it instead of argument\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/lightgbm/engine.py:123: UserWarning:\n",
            "\n",
            "Found `early_stopping_rounds` in params. Will use it instead of argument\n",
            "\n",
            "\u001b[32m[I 2021-05-30 06:51:45,927]\u001b[0m Trial 51 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/lightgbm/engine.py:118: UserWarning:\n",
            "\n",
            "Found `num_iterations` in params. Will use it instead of argument\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/lightgbm/engine.py:123: UserWarning:\n",
            "\n",
            "Found `early_stopping_rounds` in params. Will use it instead of argument\n",
            "\n",
            "\u001b[32m[I 2021-05-30 06:51:46,108]\u001b[0m Trial 52 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/lightgbm/engine.py:118: UserWarning:\n",
            "\n",
            "Found `num_iterations` in params. Will use it instead of argument\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/lightgbm/engine.py:123: UserWarning:\n",
            "\n",
            "Found `early_stopping_rounds` in params. Will use it instead of argument\n",
            "\n",
            "\u001b[32m[I 2021-05-30 06:51:48,787]\u001b[0m Trial 53 finished with value: 0.854944124756843 and parameters: {'bagging_fraction': 0.12033925693487, 'min_gain_to_split': 0.06776568245740866, 'lambda_l1': 0.6728928607175834, 'lambda_l2': 5.203480448915511e-06, 'num_leaves': 32, 'num_iterations': 330, 'early_stopping_rounds': 90, 'learning_rate': 0.3413894434978873, 'n_estimators': 770}. Best is trial 22 with value: 0.8565231192466406.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/lightgbm/engine.py:118: UserWarning:\n",
            "\n",
            "Found `num_iterations` in params. Will use it instead of argument\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/lightgbm/engine.py:123: UserWarning:\n",
            "\n",
            "Found `early_stopping_rounds` in params. Will use it instead of argument\n",
            "\n",
            "\u001b[32m[I 2021-05-30 06:51:49,162]\u001b[0m Trial 54 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/lightgbm/engine.py:118: UserWarning:\n",
            "\n",
            "Found `num_iterations` in params. Will use it instead of argument\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/lightgbm/engine.py:123: UserWarning:\n",
            "\n",
            "Found `early_stopping_rounds` in params. Will use it instead of argument\n",
            "\n",
            "\u001b[32m[I 2021-05-30 06:51:50,337]\u001b[0m Trial 55 finished with value: 0.8557743177360149 and parameters: {'bagging_fraction': 0.1489721966487753, 'min_gain_to_split': 0.30551550421436835, 'lambda_l1': 0.017861973463364787, 'lambda_l2': 0.0012787601779070267, 'num_leaves': 15, 'num_iterations': 62, 'early_stopping_rounds': 30, 'learning_rate': 0.3959580198998011, 'n_estimators': 907}. Best is trial 22 with value: 0.8565231192466406.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/lightgbm/engine.py:118: UserWarning:\n",
            "\n",
            "Found `num_iterations` in params. Will use it instead of argument\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/lightgbm/engine.py:123: UserWarning:\n",
            "\n",
            "Found `early_stopping_rounds` in params. Will use it instead of argument\n",
            "\n",
            "\u001b[32m[I 2021-05-30 06:51:50,624]\u001b[0m Trial 56 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/lightgbm/engine.py:118: UserWarning:\n",
            "\n",
            "Found `num_iterations` in params. Will use it instead of argument\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/lightgbm/engine.py:123: UserWarning:\n",
            "\n",
            "Found `early_stopping_rounds` in params. Will use it instead of argument\n",
            "\n",
            "\u001b[32m[I 2021-05-30 06:51:50,798]\u001b[0m Trial 57 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/lightgbm/engine.py:118: UserWarning:\n",
            "\n",
            "Found `num_iterations` in params. Will use it instead of argument\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/lightgbm/engine.py:123: UserWarning:\n",
            "\n",
            "Found `early_stopping_rounds` in params. Will use it instead of argument\n",
            "\n",
            "\u001b[32m[I 2021-05-30 06:51:51,402]\u001b[0m Trial 58 pruned. Trial was pruned at iteration 18.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/lightgbm/engine.py:118: UserWarning:\n",
            "\n",
            "Found `num_iterations` in params. Will use it instead of argument\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/lightgbm/engine.py:123: UserWarning:\n",
            "\n",
            "Found `early_stopping_rounds` in params. Will use it instead of argument\n",
            "\n",
            "\u001b[32m[I 2021-05-30 06:51:51,754]\u001b[0m Trial 59 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/lightgbm/engine.py:118: UserWarning:\n",
            "\n",
            "Found `num_iterations` in params. Will use it instead of argument\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/lightgbm/engine.py:123: UserWarning:\n",
            "\n",
            "Found `early_stopping_rounds` in params. Will use it instead of argument\n",
            "\n",
            "\u001b[32m[I 2021-05-30 06:51:52,145]\u001b[0m Trial 60 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/lightgbm/engine.py:118: UserWarning:\n",
            "\n",
            "Found `num_iterations` in params. Will use it instead of argument\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/lightgbm/engine.py:123: UserWarning:\n",
            "\n",
            "Found `early_stopping_rounds` in params. Will use it instead of argument\n",
            "\n",
            "\u001b[32m[I 2021-05-30 06:51:52,416]\u001b[0m Trial 61 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/lightgbm/engine.py:118: UserWarning:\n",
            "\n",
            "Found `num_iterations` in params. Will use it instead of argument\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/lightgbm/engine.py:123: UserWarning:\n",
            "\n",
            "Found `early_stopping_rounds` in params. Will use it instead of argument\n",
            "\n",
            "\u001b[32m[I 2021-05-30 06:51:52,725]\u001b[0m Trial 62 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/lightgbm/engine.py:118: UserWarning:\n",
            "\n",
            "Found `num_iterations` in params. Will use it instead of argument\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/lightgbm/engine.py:123: UserWarning:\n",
            "\n",
            "Found `early_stopping_rounds` in params. Will use it instead of argument\n",
            "\n",
            "\u001b[32m[I 2021-05-30 06:51:53,147]\u001b[0m Trial 63 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/lightgbm/engine.py:118: UserWarning:\n",
            "\n",
            "Found `num_iterations` in params. Will use it instead of argument\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/lightgbm/engine.py:123: UserWarning:\n",
            "\n",
            "Found `early_stopping_rounds` in params. Will use it instead of argument\n",
            "\n",
            "\u001b[32m[I 2021-05-30 06:51:53,472]\u001b[0m Trial 64 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/lightgbm/engine.py:118: UserWarning:\n",
            "\n",
            "Found `num_iterations` in params. Will use it instead of argument\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/lightgbm/engine.py:123: UserWarning:\n",
            "\n",
            "Found `early_stopping_rounds` in params. Will use it instead of argument\n",
            "\n",
            "\u001b[32m[I 2021-05-30 06:51:53,785]\u001b[0m Trial 65 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/lightgbm/engine.py:118: UserWarning:\n",
            "\n",
            "Found `num_iterations` in params. Will use it instead of argument\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/lightgbm/engine.py:123: UserWarning:\n",
            "\n",
            "Found `early_stopping_rounds` in params. Will use it instead of argument\n",
            "\n",
            "\u001b[32m[I 2021-05-30 06:51:55,098]\u001b[0m Trial 66 finished with value: 0.8558719874982704 and parameters: {'bagging_fraction': 0.02223641620833441, 'min_gain_to_split': 0.012377954560223942, 'lambda_l1': 0.037289780207754746, 'lambda_l2': 0.0015427939214020501, 'num_leaves': 26, 'num_iterations': 205, 'early_stopping_rounds': 25, 'learning_rate': 0.28424257192999985, 'n_estimators': 852}. Best is trial 22 with value: 0.8565231192466406.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/lightgbm/engine.py:118: UserWarning:\n",
            "\n",
            "Found `num_iterations` in params. Will use it instead of argument\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/lightgbm/engine.py:123: UserWarning:\n",
            "\n",
            "Found `early_stopping_rounds` in params. Will use it instead of argument\n",
            "\n",
            "\u001b[32m[I 2021-05-30 06:51:55,479]\u001b[0m Trial 67 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/lightgbm/engine.py:118: UserWarning:\n",
            "\n",
            "Found `num_iterations` in params. Will use it instead of argument\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/lightgbm/engine.py:123: UserWarning:\n",
            "\n",
            "Found `early_stopping_rounds` in params. Will use it instead of argument\n",
            "\n",
            "\u001b[32m[I 2021-05-30 06:51:55,769]\u001b[0m Trial 68 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/lightgbm/engine.py:118: UserWarning:\n",
            "\n",
            "Found `num_iterations` in params. Will use it instead of argument\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/lightgbm/engine.py:123: UserWarning:\n",
            "\n",
            "Found `early_stopping_rounds` in params. Will use it instead of argument\n",
            "\n",
            "\u001b[32m[I 2021-05-30 06:51:56,246]\u001b[0m Trial 69 pruned. Trial was pruned at iteration 15.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/lightgbm/engine.py:118: UserWarning:\n",
            "\n",
            "Found `num_iterations` in params. Will use it instead of argument\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/lightgbm/engine.py:123: UserWarning:\n",
            "\n",
            "Found `early_stopping_rounds` in params. Will use it instead of argument\n",
            "\n",
            "\u001b[32m[I 2021-05-30 06:51:56,664]\u001b[0m Trial 70 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/lightgbm/engine.py:118: UserWarning:\n",
            "\n",
            "Found `num_iterations` in params. Will use it instead of argument\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/lightgbm/engine.py:123: UserWarning:\n",
            "\n",
            "Found `early_stopping_rounds` in params. Will use it instead of argument\n",
            "\n",
            "\u001b[32m[I 2021-05-30 06:51:56,941]\u001b[0m Trial 71 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/lightgbm/engine.py:118: UserWarning:\n",
            "\n",
            "Found `num_iterations` in params. Will use it instead of argument\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/lightgbm/engine.py:123: UserWarning:\n",
            "\n",
            "Found `early_stopping_rounds` in params. Will use it instead of argument\n",
            "\n",
            "\u001b[32m[I 2021-05-30 06:51:57,260]\u001b[0m Trial 72 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/lightgbm/engine.py:118: UserWarning:\n",
            "\n",
            "Found `num_iterations` in params. Will use it instead of argument\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/lightgbm/engine.py:123: UserWarning:\n",
            "\n",
            "Found `early_stopping_rounds` in params. Will use it instead of argument\n",
            "\n",
            "\u001b[32m[I 2021-05-30 06:51:57,564]\u001b[0m Trial 73 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/lightgbm/engine.py:118: UserWarning:\n",
            "\n",
            "Found `num_iterations` in params. Will use it instead of argument\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/lightgbm/engine.py:123: UserWarning:\n",
            "\n",
            "Found `early_stopping_rounds` in params. Will use it instead of argument\n",
            "\n",
            "\u001b[32m[I 2021-05-30 06:51:57,843]\u001b[0m Trial 74 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/lightgbm/engine.py:118: UserWarning:\n",
            "\n",
            "Found `num_iterations` in params. Will use it instead of argument\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/lightgbm/engine.py:123: UserWarning:\n",
            "\n",
            "Found `early_stopping_rounds` in params. Will use it instead of argument\n",
            "\n",
            "\u001b[32m[I 2021-05-30 06:51:58,164]\u001b[0m Trial 75 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/lightgbm/engine.py:118: UserWarning:\n",
            "\n",
            "Found `num_iterations` in params. Will use it instead of argument\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/lightgbm/engine.py:123: UserWarning:\n",
            "\n",
            "Found `early_stopping_rounds` in params. Will use it instead of argument\n",
            "\n",
            "\u001b[32m[I 2021-05-30 06:52:00,227]\u001b[0m Trial 76 finished with value: 0.8550336553722439 and parameters: {'bagging_fraction': 0.04002267446346886, 'min_gain_to_split': 0.041755855610627814, 'lambda_l1': 3.567739439392757e-05, 'lambda_l2': 0.005003366723282663, 'num_leaves': 13, 'num_iterations': 316, 'early_stopping_rounds': 72, 'learning_rate': 0.5676663242154065, 'n_estimators': 912}. Best is trial 22 with value: 0.8565231192466406.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/lightgbm/engine.py:118: UserWarning:\n",
            "\n",
            "Found `num_iterations` in params. Will use it instead of argument\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/lightgbm/engine.py:123: UserWarning:\n",
            "\n",
            "Found `early_stopping_rounds` in params. Will use it instead of argument\n",
            "\n",
            "\u001b[32m[I 2021-05-30 06:52:00,508]\u001b[0m Trial 77 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/lightgbm/engine.py:118: UserWarning:\n",
            "\n",
            "Found `num_iterations` in params. Will use it instead of argument\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/lightgbm/engine.py:123: UserWarning:\n",
            "\n",
            "Found `early_stopping_rounds` in params. Will use it instead of argument\n",
            "\n",
            "\u001b[32m[I 2021-05-30 06:52:00,831]\u001b[0m Trial 78 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/lightgbm/engine.py:118: UserWarning:\n",
            "\n",
            "Found `num_iterations` in params. Will use it instead of argument\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/lightgbm/engine.py:123: UserWarning:\n",
            "\n",
            "Found `early_stopping_rounds` in params. Will use it instead of argument\n",
            "\n",
            "\u001b[32m[I 2021-05-30 06:52:01,160]\u001b[0m Trial 79 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/lightgbm/engine.py:118: UserWarning:\n",
            "\n",
            "Found `num_iterations` in params. Will use it instead of argument\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/lightgbm/engine.py:123: UserWarning:\n",
            "\n",
            "Found `early_stopping_rounds` in params. Will use it instead of argument\n",
            "\n",
            "\u001b[32m[I 2021-05-30 06:52:01,551]\u001b[0m Trial 80 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/lightgbm/engine.py:118: UserWarning:\n",
            "\n",
            "Found `num_iterations` in params. Will use it instead of argument\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/lightgbm/engine.py:123: UserWarning:\n",
            "\n",
            "Found `early_stopping_rounds` in params. Will use it instead of argument\n",
            "\n",
            "\u001b[32m[I 2021-05-30 06:52:04,169]\u001b[0m Trial 81 finished with value: 0.8560673270227814 and parameters: {'bagging_fraction': 0.06583663488761751, 'min_gain_to_split': 0.018507711827342774, 'lambda_l1': 0.002305484706702175, 'lambda_l2': 1.5006920819607001, 'num_leaves': 22, 'num_iterations': 314, 'early_stopping_rounds': 88, 'learning_rate': 0.36669673384722457, 'n_estimators': 857}. Best is trial 22 with value: 0.8565231192466406.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/lightgbm/engine.py:118: UserWarning:\n",
            "\n",
            "Found `num_iterations` in params. Will use it instead of argument\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/lightgbm/engine.py:123: UserWarning:\n",
            "\n",
            "Found `early_stopping_rounds` in params. Will use it instead of argument\n",
            "\n",
            "\u001b[32m[I 2021-05-30 06:52:04,414]\u001b[0m Trial 82 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/lightgbm/engine.py:118: UserWarning:\n",
            "\n",
            "Found `num_iterations` in params. Will use it instead of argument\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/lightgbm/engine.py:123: UserWarning:\n",
            "\n",
            "Found `early_stopping_rounds` in params. Will use it instead of argument\n",
            "\n",
            "\u001b[32m[I 2021-05-30 06:52:04,713]\u001b[0m Trial 83 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/lightgbm/engine.py:118: UserWarning:\n",
            "\n",
            "Found `num_iterations` in params. Will use it instead of argument\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/lightgbm/engine.py:123: UserWarning:\n",
            "\n",
            "Found `early_stopping_rounds` in params. Will use it instead of argument\n",
            "\n",
            "\u001b[32m[I 2021-05-30 06:52:04,989]\u001b[0m Trial 84 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/lightgbm/engine.py:118: UserWarning:\n",
            "\n",
            "Found `num_iterations` in params. Will use it instead of argument\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/lightgbm/engine.py:123: UserWarning:\n",
            "\n",
            "Found `early_stopping_rounds` in params. Will use it instead of argument\n",
            "\n",
            "\u001b[32m[I 2021-05-30 06:52:05,367]\u001b[0m Trial 85 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/lightgbm/engine.py:118: UserWarning:\n",
            "\n",
            "Found `num_iterations` in params. Will use it instead of argument\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/lightgbm/engine.py:123: UserWarning:\n",
            "\n",
            "Found `early_stopping_rounds` in params. Will use it instead of argument\n",
            "\n",
            "\u001b[32m[I 2021-05-30 06:52:05,713]\u001b[0m Trial 86 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/lightgbm/engine.py:118: UserWarning:\n",
            "\n",
            "Found `num_iterations` in params. Will use it instead of argument\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/lightgbm/engine.py:123: UserWarning:\n",
            "\n",
            "Found `early_stopping_rounds` in params. Will use it instead of argument\n",
            "\n",
            "\u001b[32m[I 2021-05-30 06:52:06,031]\u001b[0m Trial 87 pruned. Trial was pruned at iteration 11.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/lightgbm/engine.py:118: UserWarning:\n",
            "\n",
            "Found `num_iterations` in params. Will use it instead of argument\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/lightgbm/engine.py:123: UserWarning:\n",
            "\n",
            "Found `early_stopping_rounds` in params. Will use it instead of argument\n",
            "\n",
            "\u001b[32m[I 2021-05-30 06:52:06,295]\u001b[0m Trial 88 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/lightgbm/engine.py:118: UserWarning:\n",
            "\n",
            "Found `num_iterations` in params. Will use it instead of argument\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/lightgbm/engine.py:123: UserWarning:\n",
            "\n",
            "Found `early_stopping_rounds` in params. Will use it instead of argument\n",
            "\n",
            "\u001b[32m[I 2021-05-30 06:52:06,677]\u001b[0m Trial 89 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/lightgbm/engine.py:118: UserWarning:\n",
            "\n",
            "Found `num_iterations` in params. Will use it instead of argument\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/lightgbm/engine.py:123: UserWarning:\n",
            "\n",
            "Found `early_stopping_rounds` in params. Will use it instead of argument\n",
            "\n",
            "\u001b[32m[I 2021-05-30 06:52:06,854]\u001b[0m Trial 90 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/lightgbm/engine.py:118: UserWarning:\n",
            "\n",
            "Found `num_iterations` in params. Will use it instead of argument\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/lightgbm/engine.py:123: UserWarning:\n",
            "\n",
            "Found `early_stopping_rounds` in params. Will use it instead of argument\n",
            "\n",
            "\u001b[32m[I 2021-05-30 06:52:07,320]\u001b[0m Trial 91 pruned. Trial was pruned at iteration 15.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/lightgbm/engine.py:118: UserWarning:\n",
            "\n",
            "Found `num_iterations` in params. Will use it instead of argument\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/lightgbm/engine.py:123: UserWarning:\n",
            "\n",
            "Found `early_stopping_rounds` in params. Will use it instead of argument\n",
            "\n",
            "\u001b[32m[I 2021-05-30 06:52:07,651]\u001b[0m Trial 92 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/lightgbm/engine.py:118: UserWarning:\n",
            "\n",
            "Found `num_iterations` in params. Will use it instead of argument\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/lightgbm/engine.py:123: UserWarning:\n",
            "\n",
            "Found `early_stopping_rounds` in params. Will use it instead of argument\n",
            "\n",
            "\u001b[32m[I 2021-05-30 06:52:10,264]\u001b[0m Trial 93 finished with value: 0.8564580060718036 and parameters: {'bagging_fraction': 0.08446517497078682, 'min_gain_to_split': 0.020840450147986033, 'lambda_l1': 0.004172797870262865, 'lambda_l2': 0.5080485790648694, 'num_leaves': 19, 'num_iterations': 313, 'early_stopping_rounds': 91, 'learning_rate': 0.40728425054786277, 'n_estimators': 952}. Best is trial 22 with value: 0.8565231192466406.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/lightgbm/engine.py:118: UserWarning:\n",
            "\n",
            "Found `num_iterations` in params. Will use it instead of argument\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/lightgbm/engine.py:123: UserWarning:\n",
            "\n",
            "Found `early_stopping_rounds` in params. Will use it instead of argument\n",
            "\n",
            "\u001b[32m[I 2021-05-30 06:52:12,733]\u001b[0m Trial 94 finished with value: 0.8545046108266932 and parameters: {'bagging_fraction': 0.09387320963384538, 'min_gain_to_split': 0.024985401971326815, 'lambda_l1': 0.004484888122096258, 'lambda_l2': 0.07742817367099669, 'num_leaves': 23, 'num_iterations': 449, 'early_stopping_rounds': 98, 'learning_rate': 0.6040278120788927, 'n_estimators': 919}. Best is trial 22 with value: 0.8565231192466406.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/lightgbm/engine.py:118: UserWarning:\n",
            "\n",
            "Found `num_iterations` in params. Will use it instead of argument\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/lightgbm/engine.py:123: UserWarning:\n",
            "\n",
            "Found `early_stopping_rounds` in params. Will use it instead of argument\n",
            "\n",
            "\u001b[32m[I 2021-05-30 06:52:13,022]\u001b[0m Trial 95 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/lightgbm/engine.py:118: UserWarning:\n",
            "\n",
            "Found `num_iterations` in params. Will use it instead of argument\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/lightgbm/engine.py:123: UserWarning:\n",
            "\n",
            "Found `early_stopping_rounds` in params. Will use it instead of argument\n",
            "\n",
            "\u001b[32m[I 2021-05-30 06:52:13,344]\u001b[0m Trial 96 pruned. Trial was pruned at iteration 11.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/lightgbm/engine.py:118: UserWarning:\n",
            "\n",
            "Found `num_iterations` in params. Will use it instead of argument\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/lightgbm/engine.py:123: UserWarning:\n",
            "\n",
            "Found `early_stopping_rounds` in params. Will use it instead of argument\n",
            "\n",
            "\u001b[32m[I 2021-05-30 06:52:13,583]\u001b[0m Trial 97 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/lightgbm/engine.py:118: UserWarning:\n",
            "\n",
            "Found `num_iterations` in params. Will use it instead of argument\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/lightgbm/engine.py:123: UserWarning:\n",
            "\n",
            "Found `early_stopping_rounds` in params. Will use it instead of argument\n",
            "\n",
            "\u001b[32m[I 2021-05-30 06:52:13,903]\u001b[0m Trial 98 pruned. Trial was pruned at iteration 10.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/lightgbm/engine.py:118: UserWarning:\n",
            "\n",
            "Found `num_iterations` in params. Will use it instead of argument\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/lightgbm/engine.py:123: UserWarning:\n",
            "\n",
            "Found `early_stopping_rounds` in params. Will use it instead of argument\n",
            "\n",
            "\u001b[32m[I 2021-05-30 06:52:14,199]\u001b[0m Trial 99 pruned. Trial was pruned at iteration 10.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Best trial:\n",
            "  Params: \n",
            "    bagging_fraction: 0.12662479766833926\n",
            "    min_gain_to_split: 0.030464234692411756\n",
            "    lambda_l1: 2.239568718793956e-05\n",
            "    lambda_l2: 0.00023743417157968223\n",
            "    num_leaves: 35\n",
            "    num_iterations: 170\n",
            "    early_stopping_rounds: 84\n",
            "    learning_rate: 0.22805917008732526\n",
            "    n_estimators: 867\n",
            "0.7245402188688586\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.98      0.91     93718\n",
            "           1       0.87      0.47      0.61     29144\n",
            "\n",
            "    accuracy                           0.86    122862\n",
            "   macro avg       0.86      0.72      0.76    122862\n",
            "weighted avg       0.86      0.86      0.84    122862\n",
            "\n",
            "0.723896256458027\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.98      0.91     93719\n",
            "           1       0.86      0.47      0.61     29144\n",
            "\n",
            "    accuracy                           0.86    122863\n",
            "   macro avg       0.86      0.72      0.76    122863\n",
            "weighted avg       0.86      0.86      0.84    122863\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sFKZ08RGNJVn",
        "outputId": "c4b591f5-073b-4ab9-90c9-d2410c02c51c"
      },
      "source": [
        "X_test_norm1=X_test_norm.drop(['ID','Credit_Product'],axis=1)\n",
        "test_preds = np.rint(best_model.predict(X_test_norm1))\n",
        "test_pred=pd.DataFrame(test_preds)\n",
        "test_pred.value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0    103355\n",
              "1.0      1957\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Humu8JuXeFfG"
      },
      "source": [
        "gbm = lgb.train(\n",
        "             train_set=dtrain, valid_sets=[dvalid], verbose_eval=False \\\n",
        "             ,params={}, num_boost_round=1000\n",
        "        )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iEmTunvqeawo",
        "outputId": "8776c784-d456-406c-f72f-6a9dfd643e94"
      },
      "source": [
        "new_preds = gbm.predict(train_x)\n",
        "new_pred_labels = np.rint(new_preds)\n",
        "print(sklearn.metrics.accuracy_score(train_y, new_pred_labels))\n",
        "print(sklearn.metrics.classification_report(train_y, new_pred_labels))\n",
        "new_preds = gbm.predict(valid_x)\n",
        "new_pred_labels = np.rint(new_preds)\n",
        "print(sklearn.metrics.accuracy_score(valid_y, new_pred_labels))\n",
        "print(sklearn.metrics.classification_report(valid_y, new_pred_labels))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.8800281383897167\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.89      0.97      0.92    131206\n",
            "           1       0.85      0.60      0.70     40801\n",
            "\n",
            "    accuracy                           0.88    172007\n",
            "   macro avg       0.87      0.78      0.81    172007\n",
            "weighted avg       0.88      0.88      0.87    172007\n",
            "\n",
            "0.859762880164953\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      0.95      0.91     56231\n",
            "           1       0.79      0.55      0.65     17487\n",
            "\n",
            "    accuracy                           0.86     73718\n",
            "   macro avg       0.83      0.75      0.78     73718\n",
            "weighted avg       0.85      0.86      0.85     73718\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4tAo2a4BUSIa"
      },
      "source": [
        "ID=pd.DataFrame(X_test_norm.ID.astype(object))\n",
        "lead= pd.DataFrame(test_pred.astype(int))\n",
        "test_df=pd.concat([ID,lead],axis=1)\n",
        "test_df.columns=['ID','Is_Lead']\n",
        "test_df=test_df\n",
        "# test_df=pd.DataFrame([X_test_norm.ID.astype(object),test_pred.astype(int)],index=['ID','Is_Lead']).T"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 110
        },
        "id": "w55wRZJQUpmv",
        "outputId": "c673e505-75ff-4e99-99e7-0b32c2e9be24"
      },
      "source": [
        "test_df.head(2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "      <th>Is_Lead</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>VBENBARO</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>CCMEWNKY</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         ID  Is_Lead\n",
              "0  VBENBARO        0\n",
              "1  CCMEWNKY        1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 242
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "WVUlFtk9T54i",
        "outputId": "d7e91e33-aeca-4729-be79-944cfab2c304"
      },
      "source": [
        "test_df.to_csv('jobathon_Submission.csv',index=False)\n",
        "from google.colab import files\n",
        "files.download('jobathon_Submission.csv')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_a62560d9-9250-41e7-b11b-d9d82cef1ca2\", \"jobathon_Submission.csv\", 1158443)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "18M0oMMKUtSP"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}